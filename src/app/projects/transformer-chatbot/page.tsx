import Image from "next/image"
import TextLink from "@/app/components/TextLink"

const TransformerPage= () => {
    return (
        <>
            <p className='font-bold text-3xl mb-3'>transformer-chatbot</p>

            <p className="font-semibold mt-1 text-lg">Description</p>
            <p className='mt-2 mb-1'><TextLink name="transformer-chatbot " target="https://github.com/jensonjenkins/transformer-chatbot" blank={true} />
                is a chatbot which uses the encoder-decoder transformer architecture proposed by A. Vaswani and his team in their paper, "Attention is All You Need".</p>
            <p className="mt-1 mb-3">In this project,
                I've implemented their findings by building and training the
                <TextLink
                    name=" architecture"
                    target="https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png"
                    blank={true} />.
                The model is ~36M parameters large, trained against ~1.4M instances of the 
                <TextLink
                    name=" LaMini-instruction "
                    target="https://huggingface.co/datasets/MBZUAI/LaMini-instructionhttps://press.liacs.nl/mirflickr/mirdownload.html"
                    blank={true} /> dataset.</p>

            <div className="flex flex-row mt-3 p-2 border rounded-lg">

                <Image
                    alt="transformer-chatbot demo"
                    src="/tchabot1.jpg"
                    width={700}
                    height={465}/>
            </div>
            <p className="italic text-gray-400 text-center font-light text-sm my-1">Real examples generated by 
            <TextLink name=" transformer-chatbot" target="https://github.com/jensonjenkins/transformer-chatbot" blank={true} /> </p>

            <p className="font-semibold mt-4  text-lg">Technology and Tools</p>

            <p className="mt-1 ">&nbsp;&nbsp;&#x2022; Model built using <TextLink name="Tensorflow" target="https://www.tensorflow.org/" blank={true}/>, 
            utilizing <TextLink name="Tensorflow Text " target="https://www.tensorflow.org/text" blank={true}/>for sub-word tokenization</p>
            <p className="mt-1">&nbsp;&nbsp;&#x2022; Written in Python through object-oriented programming practices</p>
            <p className="mt-1">&nbsp;&nbsp;&#x2022; Trained by utilizing Google Colab's Nvidia Tesla T4s</p>
            <p className="mt-1">&nbsp;&nbsp;&#x2022; Containerized in <TextLink name="Docker" target="https://www.docker.com/" blank={true}/> to operate on local machines</p>
        </>
    )
}

export default TransformerPage